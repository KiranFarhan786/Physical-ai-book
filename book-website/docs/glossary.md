# Glossary: Robotics and AI Terms

## A

**Actuator**: A component of a robot responsible for moving and controlling a mechanism or system.

**AI (Artificial Intelligence)**: The simulation of human intelligence processes by machines, especially computer systems.

## B

**Behavior Tree**: A mathematical model of action organization that is used to govern the behavior of an autonomous entity in robotics and AI.

## C

**Computer Vision**: A field of artificial intelligence that trains computers to interpret and understand the visual world.

## D

**DDS (Data Distribution Service)**: A middleware protocol and API standard for distributed real-time systems, used in ROS 2.

**Deep Learning**: A subset of machine learning that uses neural networks with multiple layers to model and understand complex patterns.

## E

**Embodied Intelligence**: Intelligence that emerges from the interaction between an agent and its physical environment.

## F

**Forward Kinematics**: The use of joint angles to determine the position and orientation of the end effector of a robotic arm.

## G

**Gazebo**: A 3D simulation environment for robotics that provides physics simulation and sensor integration.

## H

**Humanoid Robot**: A robot with human-like features and structure, typically having a head, torso, two arms, and two legs.

## I

**Inverse Kinematics**: The mathematical process of determining the joint parameters needed to place the end of a robotic arm in a specific position.

**Isaac ROS**: NVIDIA's collection of hardware-accelerated perception and navigation packages for robotics applications.

## L

**LiDAR (Light Detection and Ranging)**: A remote sensing method that uses light in the form of a pulsed laser to measure distances.

**LLM (Large Language Model)**: A type of language model that uses deep learning to understand and generate human language.

## M

**Middleware**: Software that provides common services and capabilities to applications beyond what's offered by the operating system.

## N

**Nav2 (Navigation 2)**: The navigation stack for ROS 2 that provides path planning and obstacle avoidance capabilities.

**Neural Network**: A series of algorithms that endeavors to recognize underlying relationships in a set of data through a process that mimics the way the human brain operates.

## P

**Perception**: The process by which robots interpret sensor data to understand their environment.

**PID Controller (Proportional-Integral-Derivative Controller)**: A control loop mechanism that uses error feedback to control process variables.

## R

**Robotics**: The branch of technology that deals with the design, construction, operation, and application of robots.

**ROS (Robot Operating System)**: A flexible framework for writing robot software that provides a collection of tools, libraries, and conventions.

**ROS 2**: The second generation of the Robot Operating System, designed for production environments with improved security and real-time capabilities.

## S

**Sensor Fusion**: The process of combining data from multiple sensors to improve the accuracy and reliability of information.

**SLAM (Simultaneous Localization and Mapping)**: The computational problem of constructing or updating a map of an unknown environment while simultaneously keeping track of an agent's location within it.

**Simulation**: The process of creating a model of a real-world system to analyze its behavior under various conditions.

## T

**Topic**: In ROS, a named bus over which nodes exchange messages.

## U

**URDF (Unified Robot Description Format)**: An XML format for representing a robot model in ROS.

## V

**VLA (Vision-Language-Action)**: A paradigm that combines visual perception, language understanding, and physical action in robotics.

**VSLAM (Visual Simultaneous Localization and Mapping)**: SLAM using visual sensors such as cameras.

## W

**Whisper**: OpenAI's automatic speech recognition system that can transcribe speech in multiple languages.